{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46a7ee11",
   "metadata": {},
   "source": [
    "## Notebook Description: Model Predictions on Documents\n",
    "\n",
    "This Jupyter notebook demonstrates the evaluation and visualization of trained segmentation models on document datasets. The notebook:\n",
    "\n",
    "**Purpose**: Tests and visualizes predictions from pre-trained segmentation models (LUNet and UNet) on document images.\n",
    "\n",
    "**Key Features**:\n",
    "- Loads pre-trained models from checkpoints for different datasets (UTP and splitAB1)\n",
    "- Supports both from-scratch and fine-tuned model variants\n",
    "- Generates predictions on test datasets and compares them with ground truth masks\n",
    "- Provides side-by-side visualization of original images, ground truth masks, and model predictions\n",
    "\n",
    "**Workflow**:\n",
    "1. Configures dataset parameters and model paths based on dataset type\n",
    "2. Loads the appropriate pre-trained model (LUNet or UNet) with specified epochs\n",
    "3. Processes test data and generates predictions\n",
    "4. Visualizes results comparing original images, ground truth, and predictions\n",
    "\n",
    "**Datasets**: Works with UTP and splitAB1 document segmentation datasets, with different output channel configurations (7 channels for UTP, 4 for splitAB1).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8de6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import os\n",
    "from sys import path\n",
    "path.append('..')\n",
    "from Modules.Dataset import generate_dataset\n",
    "\n",
    "# %%\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from Modules.Dataset import generate_dataset\n",
    "from Modules.Architecture import generate_model\n",
    "from Modules.Visualization import (\n",
    "    visualize_mask,\n",
    "    visualize_image_and_mask,\n",
    ")\n",
    "from Modules.ModelXAI import generate_XAI_model\n",
    "# %%\n",
    "dataset_type='UTP'\n",
    "dataset_type='splitAB1'\n",
    "\n",
    "base_dir: str = f\"../datasets/{dataset_type}\"\n",
    "device = 'cpu'\n",
    "device = 'cuda:0'\n",
    "\n",
    "model_type = 'lunet'\n",
    "MODEL_TAGS = [\"from_scratch_models\", \"finetuned_models_minloss\"]\n",
    "model_tag = MODEL_TAGS[0] if dataset_type == 'UTP' else MODEL_TAGS[1]\n",
    "\n",
    "OUT_CHANNELS = 7 if dataset_type == 'UTP' else 4\n",
    "\n",
    "# Dataloader\n",
    "if dataset_type == 'splitAB1':\n",
    "    _, _, test_loader = generate_dataset(\n",
    "        dataset_type=dataset_type,\n",
    "        base_dir=base_dir,\n",
    "        **{\n",
    "            \"train_folder\": \"training-40\",\n",
    "            \"validation_folder\": \"validation\",\n",
    "            \"test_folder\": \"test\",\n",
    "        }\n",
    "    )\n",
    "else:\n",
    "    _, _, test_loader = generate_dataset(\n",
    "        dataset_type=dataset_type,\n",
    "        base_dir=base_dir,\n",
    "        **{\n",
    "            \"train_folder\": \"Training\",\n",
    "            \"validation_folder\": \"Validation\",\n",
    "            \"test_folder\": \"Test\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "UTP_EPOCHS_DICT = {\n",
    "    \"lunet\": {MODEL_TAGS[0]: 84, MODEL_TAGS[1]: 61},\n",
    "    \"unet\": {MODEL_TAGS[0]: 85, MODEL_TAGS[1]: 43},\n",
    "}\n",
    "\n",
    "\n",
    "CB55_EPOCHS_DICT = {\n",
    "    \"lunet\": {MODEL_TAGS[0]: 108, MODEL_TAGS[1]: 40},\n",
    "    \"unet\": {MODEL_TAGS[0]: 60, MODEL_TAGS[1]: 87},\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "if dataset_type == 'UTP':\n",
    "    models_path = f\"../models/{dataset_type}/{model_type}/{model_tag}\"\n",
    "    model_name = f\"model{UTP_EPOCHS_DICT[model_type][model_tag]}.pt\"\n",
    "else:\n",
    "    models_path = f\"../models/{dataset_type}/{model_type}/{model_tag}\"\n",
    "    model_name = f\"model{CB55_EPOCHS_DICT[model_type][model_tag]}.pt\"\n",
    "\n",
    "print(f\"Loading model from {models_path}\")\n",
    "print(f\"Model name: {model_name}\")\n",
    "\n",
    "\n",
    "# %%\n",
    "print(\"Loading model...\")\n",
    "model = generate_model(\n",
    "    model_type= model_type, \n",
    "    out_channels=OUT_CHANNELS, \n",
    "    load_from_checkpoint=True,\n",
    "    models_path=models_path, \n",
    "    checkpoint_name=model_name\n",
    ").eval().to(device)\n",
    "\n",
    "# Prepare model for XAI\n",
    "model = generate_XAI_model(model=model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ee9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (image_batch, mask_batch, paths) in tqdm(enumerate(test_loader)):\n",
    "    image_batch = image_batch.to(device, dtype=torch.float)\n",
    "    image_name = paths[0][0].split(\"/\")[-1].split(\".\")[0]\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ead2ff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73cf62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred= model(image_batch).max(dim=1)[1]\n",
    "fig,axes = plt.subplots(1,3,figsize=(8,6))\n",
    "_ = visualize_image_and_mask(image_batch.squeeze().detach().cpu(),mask_batch.detach().cpu(), dataset_type=dataset_type,fig=fig,axes=axes)\n",
    "_ = visualize_mask(pred.detach().cpu(), dataset_type=dataset_type,fig=fig,ax=axes[2]);_ =axes[2].set_title(\"Prediction\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
